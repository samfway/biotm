{
 "metadata": {
  "name": "",
  "signature": "sha256:4d4a4c42c94db1bf8abaadc34be81a1010c6b1993c579fa4b5afcba65e02b17c"
 },
 "nbformat": 3,
 "nbformat_minor": 0,
 "worksheets": [
  {
   "cells": [
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "from biotm.parse.fileio import load_dataset\n",
      "from biotm.topic_models.plsa import plsa\n",
      "import matplotlib.pyplot as plt\n",
      "from numpy import array\n",
      "from numpy.random import randint\n",
      "from sklearn.decomposition import TruncatedSVD, KernelPCA, FastICA, MiniBatchDictionaryLearning, NMF"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 36
    },
    {
     "cell_type": "heading",
     "level": 2,
     "metadata": {},
     "source": [
      "Loading and filtering of Smoking data"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "mapping_file = '/Users/samway/Documents/Work/TopicModeling/biotm/data/smoking/smoking.mapping.txt'\n",
      "otu_file = '/Users/samway/Documents/Work/TopicModeling/biotm/data/smoking/smoking.biom'\n",
      "metadata_category = 'Smoking_Simple'\n",
      "metadata_value = None\n",
      "\n",
      "otu_fp = open(otu_file, 'rU')\n",
      "map_fp = open(mapping_file, 'rU')\n",
      "\n",
      "data_matrix, sample_ids, labels, label_legend = \\\n",
      "    load_dataset(otu_fp, map_fp, metadata_category, metadata_value)\n",
      "    \n",
      "relevant_indices = array([i for i,v in enumerate(labels) if label_legend[v] != 'NA'])\n",
      "data_matrix = data_matrix[relevant_indices, :]\n",
      "sample_ids = sample_ids[relevant_indices]\n",
      "labels = labels[relevant_indices]\n",
      "\n",
      "print \"Data matrix dimensions: \", data_matrix.shape \n",
      "print \"Number of Sample IDs: \" , len(sample_ids)\n",
      "print \"Number of Labels: \", len(labels)\n",
      "print \"Sum of all counts: \", data_matrix.sum()"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "Data matrix dimensions:  (202, 793)\n",
        "Number of Sample IDs:  202\n",
        "Number of Labels:  202\n",
        "Sum of all counts:  177498.0\n"
       ]
      }
     ]
    },
    {
     "cell_type": "heading",
     "level": 2,
     "metadata": {},
     "source": [
      "PLSA on the data"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "tm = plsa(n_components=5, n_iter=1)\n",
      "p_z_d = tm.fit_transform(data_matrix, labels)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "fig, ax = plt.subplots(figsize=(10, 10), dpi=80)\n",
      "ax.scatter(p_z_d[2,:], p_z_d[0,:], c=labels, s=100, alpha=0.7)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "heading",
     "level": 2,
     "metadata": {},
     "source": [
      "Truncated SVD (PCA) on the data"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "svdm = TruncatedSVD()\n",
      "svd_coords = svdm.fit_transform(data_matrix)\n",
      "\n",
      "fig, ax = plt.subplots(figsize=(10, 10), dpi=80)\n",
      "ax.scatter(svd_coords[:,0], svd_coords[:,1], c=labels, s=100, alpha=0.7)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "heading",
     "level": 2,
     "metadata": {},
     "source": [
      "Kernel PCA on the data"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "dim_redux = KernelPCA(n_components=2)\n",
      "new_coords = dim_redux.fit_transform(data_matrix)\n",
      "\n",
      "fig, ax = plt.subplots(figsize=(10, 10), dpi=80)\n",
      "ax.scatter(new_coords[:,0], new_coords[:,1], c=labels, s=100, alpha=0.7)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "heading",
     "level": 2,
     "metadata": {},
     "source": [
      "FastICA on the data"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "dim_redux = FastICA(n_components=2)\n",
      "new_coords = dim_redux.fit_transform(data_matrix)\n",
      "\n",
      "fig, ax = plt.subplots(figsize=(10, 10), dpi=80)\n",
      "ax.scatter(new_coords[:,0], new_coords[:,1], c=labels, s=100, alpha=0.7)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "heading",
     "level": 2,
     "metadata": {},
     "source": [
      "NMF on the data"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "dim_redux = NMF(n_components=2)\n",
      "new_coords = dim_redux.fit_transform(data_matrix)\n",
      "\n",
      "fig, ax = plt.subplots(figsize=(10, 10), dpi=80)\n",
      "ax.scatter(new_coords[:,0], new_coords[:,1], c=labels, s=100, alpha=0.7)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "heading",
     "level": 1,
     "metadata": {},
     "source": [
      "Folding in data"
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "After learning a lower-dimensional semantic space from PLSA, we also need to be able to place a new document into that space.  In PLSA, this is known as \"folding in\" document vectors using the EM algorithm.  Essentially, the EM algorithm is told not to optimize or change the distributions that define the topics P(w|z) and instead maximize the likelihood of the new documents by adjusting P(z|d).  \n",
      "\n",
      "To illustrate what this looks like, we take a document from the corpus, add some error, and examine its coordinates in the semantic space as well as those of the error-free version of the document."
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "check = -4\n",
      "fold_me = data_matrix[check, :].copy()[None,:]\n",
      "fold_me.shape\n",
      "\n",
      "# Add some noise\n",
      "num_to_add = 50\n",
      "for i in xrange(num_to_add):\n",
      "    index = randint(0, fold_me.shape[1])\n",
      "    fold_me[0, index] += 1\n",
      "\n",
      "print '\\n\"New\" document:'\n",
      "print ', '.join(['%.4f' % x for x in tm.transform(fold_me)])\n",
      "print '\\nOriginal:'\n",
      "print ', '.join(['%.4f' % x for x in tm.p_z_d[:,check]])"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "...Pretty close, right?  \n"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [],
     "language": "python",
     "metadata": {},
     "outputs": []
    }
   ],
   "metadata": {}
  }
 ]
}